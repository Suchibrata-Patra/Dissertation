significance[i]= "Not Significant"
}else{
significance[i]="Significant"
}
}
data.frame(names(training_data)[-16],estimates,se,walds_t,significance)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-c(1,7)]#
se = y[,2][-c(1,7)]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:16){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],estimates,se,walds_t,significance)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-c(1,7)]#
se = y[,2][-c(1,7)]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
#Findig Out the Odds Ratio#
Odds_Ratio = exp(estimates)#
p_values = 2*(1- qnorm(estimates)) ; p_values#
data.frame(names(training_data)[-16],exp(Odds_Ratio),p_values)
reduced_model_8
y[,1][-c(1,7)]
y
se = y[,2][-c(1,7)]
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-c(1,7)]#
se = y[,2][-c(1,7)]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}
Odds_Ratio = exp(estimates)
p_values = 2*(1- qnorm(estimates)) ; p_values
data.frame(names(training_data)[-16],exp(Odds_Ratio),p_values)
data.frame(names(training_data)[-7],exp(Odds_Ratio),p_values)
data.frame(names(training_data)[-7],exp(Odds_Ratio))
Odds_Ratio
reduced_model_8
Odds_Ratio
data.frame(names(training_data),exp(Odds_Ratio))
data.frame(names(reduced_model_8),exp(Odds_Ratio))
data.frame(names(reduced_model_8),exp(Odds_Ratio))
names(reduced_model_8)
data.frame(names(reduced_data_8),exp(Odds_Ratio))
reduced_data_8
names(reduced_data_8)
Odds_Ratio
data.frame(names(reduced_data_8)[-7],exp(Odds_Ratio))
data.frame(names(reduced_data_8)[-8],exp(Odds_Ratio))
x = summary(reduced_model_8)
y = x$coefficients
estimates = y[,1][-c(1,7)]
se = y[,2][-c(1,7)]
Odds_Ratio = exp(estimates)
data.frame(names(reduced_data_8)[-8],exp(Odds_Ratio))
reduced_model_8
estimates = y[,1][-c(1,7)]
y[,1][-c(1,7)]
estimates = y[,1][c(1,7)]
y[,1][c(1,7)]
estimates = y[,1][-c(1,)]
y
y[,1]
estimates = y[,1][-1]
y[,1][-1]
se = y[,2][-1]
walds_t = as.numeric(estimates/sqrt(se))
significance = numeric(7)
#Findig Out the Odds Ratio#
Odds_Ratio = exp(estimates)#
p_values = 2*(1- qnorm(estimates)) ; p_values#
data.frame(names(reduced_data_8)[-8],exp(Odds_Ratio))
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
#Findig Out the Odds Ratio#
# Calculating odds ratios#
Odds_Ratio = exp(estimates)#
#
# Calculating p-values#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
#
# Displaying results#
results_df <- data.frame(names(reduced_data_8)[-8], Odds_Ratio, p_values)#
results_df
Odds_Ratio = exp(estimates)#
p_values = 2*(1- qnorm(estimates)) ; p_values#
data.frame(names(reduced_data_8)[-8],exp(Odds_Ratio))
Odds_Ratio = exp(estimates)
Odds_Ratio
Odds_Ratio = exp(estimates)#
p_values = 2*(1- qnorm(estimates)) ; p_values#
data.frame(names(reduced_data_8)[-8],exp(Odds_Ratio))
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
#Findig Out the Odds Ratio#
Odds_Ratio = exp(estimates)#
p_values = 2*(1- qnorm(estimates)) ; p_values#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation
Odds_Ratio = exp(estimates)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
#Findig Out the Odds Ratio#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:8){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
#Findig Out the Odds Ratio#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(7)#
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
# Calculate coefficient estimates, standard errors, Wald's t statistics, and significance#
x <- summary(reduced_model_8)#
y <- x$coefficients#
estimates <- y[,1][-1]#
se <- y[,2][-1]#
walds_t <- as.numeric(estimates/sqrt(se))#
significance <- ifelse(abs(walds_t) > 1.96, "Not Significant", "Significant")#
#
# Create data frame#
result_df <- data.frame(#
  Predictor = names(reduced_model_8)[-8],#
  Estimate = estimates,#
  Standard_Error = se,#
  Walds_t = walds_t,#
  Significance = significance#
)#
#
# Display the result data frame#
result_df
# Calculate coefficient estimates, standard errors, Wald's t statistics, and significance#
x <- summary(reduced_model_8)#
y <- x$coefficients#
estimates <- y[, 1][-1]#
se <- y[, 2][-1]#
walds_t <- as.numeric(estimates / sqrt(se))#
significance <- ifelse(abs(walds_t) > 1.96, "Not Significant", "Significant")#
#
# Create data frame#
result_df <- data.frame(#
  Predictor = names(x$coefficients)[-1],#
  Estimate = estimates,#
  Standard_Error = se,#
  Walds_t = walds_t,#
  Significance = significance#
)#
#
# Display the result data frame#
result_df
# Calculate coefficient estimates, standard errors, Wald's t statistics, and significance#
x <- summary(reduced_model_8)#
estimates <- x$coefficients[-1, 1]#
se <- x$coefficients[-1, 2]#
walds_t <- as.numeric(estimates / sqrt(se))#
significance <- ifelse(abs(walds_t) > 1.96, "Not Significant", "Significant")#
#
# Create data frame#
result_df <- data.frame(#
  Predictor = names(x$coefficients)[-1],#
  Estimate = estimates,#
  Standard_Error = se,#
  Walds_t = walds_t,#
  Significance = significance#
)#
#
# Display the result data frame#
result_df
for(i in 1:7){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}
data.frame(names(training_data)[-7],estimates,se,walds_t,significance)
significance
length(significance)
estimates
se
walds_t
length(walds_t)
length(significance)
length(estimates)
length(training_data)
data.frame(names(reduced_data_8)[-7],estimates,se,walds_t,significance)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = exp(estimates)#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
summary(reduced_model_10)
summary(reduced_model_9)
summary(reduced_model_8)
Selected_Model = reduced_model_6
fitted_prob = fitted(Selected_Model)
x = summary(fullmodel)
estimates = y[,1][-1]
estimates
se = y[,2][-1]
walds_t = as.numeric(estimates/sqrt(se))
significance = numeric(7)
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))
x = summary(fullmodel)
x
y = x$coefficients
estimates = y[,1][-1]
estimates
se = y[,2][-1]
walds_t = as.numeric(estimates/sqrt(se))
significance = numeric(15)
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-16],estimates,se,walds_t,significance)#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(reduced_data_8)[-16],Odds_Ratio)
data.frame(names(fullmodel)[-16],Odds_Ratio)
data.frame(names(data)[-16],Odds_Ratio)
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-16],estimates,se,walds_t,significance)#
Odds_Ratio = exp(estimates)#
p_values = 2 * (1 - pnorm(abs(estimates)))  # Corrected calculation#
data.frame(names(data)[-16],Odds_Ratio)
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-16],estimates,se,walds_t,significance)#
Odds_Ratio = exp(estimates)
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = exp(estimates)#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = exp(estimates)#
data.frame(names(reduced_data_8)[-8],Odds_Ratio)
data.frame(Odds_Ratio)
Odds_Ratio
Odds_Ratio = as.data.frame(exp(estimates))
Odds_Ratio
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio
Odds_Ratio
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio
summary(fullmodel)
summary(fullmodel)$accuracy
summary(fullmodel)$Accuracy
fullmodel
fullmodel$Accuracy
fullmodel$accuracy
names(fullmodel)
names(summary(fullmodel)
names(summary(fullmodel))
names(summary(fullmodel))
# Assuming you have the confusion matrix stored in a variable named "conf_matrix"#
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
binary_predictions = ifelse(fitted_prob > optimum_thresold, 1, 0)#
#
# Calculate confusion matrix#
confusion_matrix = table(binary_predictions, TenYearCHD)#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)#
#
# Calculate accuracy#
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)
TPR=array()#
FPR=array()#
Index = array()#
k=1#
p=seq(0.1,0.9,0.001)#
for(i in p)#
{#
print(paste("Threshold = ",i))#
Y.hat=ifelse(fitted_prob>i,1,0)#
confusion_matrix = table(Y.hat,training_data$TenYearCHD)#
print(confusion_matrix)#
  TN = confusion_matrix[1, 1]  # True Negatives#
  FP = confusion_matrix[1, 2]  # False Positives#
  FN = confusion_matrix[2, 1]  # False Negatives#
  TP = confusion_matrix[2, 2]  # True Positives#
  TPR[k] = TP / (TP + FN)#
  FPR[k] = FP / (TN + FP + FN + TP)#
  Index[k] = TPR[k] * (1 - FPR[k]) #
  plot(FPR,TPR,type="l",main="Finding Optimum Model . . . ")#
  k=k+1#
}#
optimum_thresold = p[which.max(Index)]#
#===================================##
#Checking the Model Accuracy        ##
#===================================##
#
binary_predictions = ifelse(fitted_prob > optimum_thresold, 1, 0)#
#
# Calculate confusion matrix#
confusion_matrix = table(binary_predictions, TenYearCHD)#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)#
#
# Calculate accuracy#
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
fitted_prob = predict(reduced_model_8)
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
TPR=array()#
FPR=array()#
Index = array()#
k=1#
p=seq(0.1,0.9,0.001)#
for(i in p)#
{#
print(paste("Threshold = ",i))#
Y.hat=ifelse(fitted_prob>i,1,0)#
confusion_matrix = table(Y.hat,training_data$TenYearCHD)#
print(confusion_matrix)#
  TN = confusion_matrix[1, 1]  # True Negatives#
  FP = confusion_matrix[1, 2]  # False Positives#
  FN = confusion_matrix[2, 1]  # False Negatives#
  TP = confusion_matrix[2, 2]  # True Positives#
  TPR[k] = TP / (TP + FN)#
  FPR[k] = FP / (TN + FP + FN + TP)#
  Index[k] = TPR[k] * (1 - FPR[k]) #
  plot(FPR,TPR,type="l",main="Finding Optimum Model . . . ")#
  k=k+1#
}#
optimum_thresold = p[which.max(Index)]#
#===================================##
#Checking the Model Accuracy        ##
#===================================##
#
binary_predictions = ifelse(fitted_prob > optimum_thresold, 1, 0)#
#
# Calculate confusion matrix#
confusion_matrix = table(binary_predictions, TenYearCHD)#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)#
#
# Calculate accuracy#
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)#
print(paste("Accuracy:", round(accuracy, 3)))
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
TPR=array()#
FPR=array()#
Index = array()#
k=1#
p=seq(0.1,0.9,0.001)#
for(i in p)#
{#
print(paste("Threshold = ",i))#
Y.hat=ifelse(fitted_prob>i,1,0)#
confusion_matrix = table(Y.hat,training_data$TenYearCHD)#
print(confusion_matrix)#
  TN = confusion_matrix[1, 1]  # True Negatives#
  FP = confusion_matrix[1, 2]  # False Positives#
  FN = confusion_matrix[2, 1]  # False Negatives#
  TP = confusion_matrix[2, 2]  # True Positives#
  TPR[k] = TP / (TP + FN)#
  FPR[k] = FP / (TN + FP + FN + TP)#
  Index[k] = TPR[k] * (1 - FPR[k]) #
  plot(FPR,TPR,type="l",main="Finding Optimum Model . . . ")#
  k=k+1#
}#
optimum_thresold = p[which.max(Index)]
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
TPR=array()#
FPR=array()#
Index = array()#
k=1#
p=seq(0.1,0.9,0.001)#
for(i in p)#
{#
print(paste("Threshold = ",i))#
Y.hat=ifelse(fitted_prob>i,1,0)#
confusion_matrix = table(Y.hat,reduced_data_8$TenYearCHD)#
print(confusion_matrix)#
  TN = confusion_matrix[1, 1]  # True Negatives#
  FP = confusion_matrix[1, 2]  # False Positives#
  FN = confusion_matrix[2, 1]  # False Negatives#
  TP = confusion_matrix[2, 2]  # True Positives#
  TPR[k] = TP / (TP + FN)#
  FPR[k] = FP / (TN + FP + FN + TP)#
  Index[k] = TPR[k] * (1 - FPR[k]) #
  plot(FPR,TPR,type="l",main="Finding Optimum Model . . . ")#
  k=k+1#
}#
optimum_thresold = p[which.max(Index)]
optimum_thresold
binary_predictions = ifelse(fitted_prob > optimum_thresold, 1, 0)#
#
# Calculate confusion matrix#
confusion_matrix = table(binary_predictions, TenYearCHD)#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)#
#
# Calculate accuracy#
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)#
print(paste("Accuracy:", round(accuracy, 3)))
summary(fullmodel)
fullmodel
names(summary(fullmodel))
summary(fullmodel)$aic
summary(fullmodel)$cov.scaled
names(summary(fullmodel))
summary(fullmodel)$df
summary(fullmodel)$coefficients
summary(fullmodel)$terms
library(pROC)#
library(caret)#
#
# Assuming you have predictions and true labels#
pred_probs <- predict(full_model, newdata = test_data, type = "response")#
true_labels <- test_data$target_variable  # Adjust this based on your data#
#
# Calculate ROC curve#
roc_curve <- roc(true_labels, pred_probs)#
#
# Plot ROC curve#
plot(roc_curve, main = "ROC Curve", col = "blue")#
abline(a = 0, b = 1, lwd = 2, lty = 2, col = "red")#
#
# Calculate AUC#
auc_value <- auc(roc_curve)#
#
# Convert predicted probabilities to binary predictions#
predictions <- ifelse(pred_probs >= 0.5, 1, 0)#
#
# Calculate confusion matrix#
conf_matrix <- confusionMatrix(data = factor(predictions, levels = c(0, 1)),#
                               reference = factor(true_labels, levels = c(0, 1)))#
#
# Extract accuracy from confusion matrix#
accuracy <- conf_matrix$overall['Accuracy']#
#
# Print AUC and accuracy#
print(paste("AUC:", auc_value))#
print(paste("Accuracy:", accuracy))
library(pROC)#
library(caret)#
#
# Assuming you have predictions and true labels#
pred_probs <- predict(fullmodel, newdata = test_data, type = "response")#
true_labels <- test_data$target_variable  # Adjust this based on your data#
#
# Calculate ROC curve#
roc_curve <- roc(true_labels, pred_probs)#
#
# Plot ROC curve#
plot(roc_curve, main = "ROC Curve", col = "blue")#
abline(a = 0, b = 1, lwd = 2, lty = 2, col = "red")#
#
# Calculate AUC#
auc_value <- auc(roc_curve)#
#
# Convert predicted probabilities to binary predictions#
predictions <- ifelse(pred_probs >= 0.5, 1, 0)#
#
# Calculate confusion matrix#
conf_matrix <- confusionMatrix(data = factor(predictions, levels = c(0, 1)),#
                               reference = factor(true_labels, levels = c(0, 1)))#
#
# Extract accuracy from confusion matrix#
accuracy <- conf_matrix$overall['Accuracy']#
#
# Print AUC and accuracy#
print(paste("AUC:", auc_value))#
print(paste("Accuracy:", accuracy))
library(pROC)#
library(caret)#
#
# Assuming you have predictions and true labels#
pred_probs <- predict(fullmodel, newdata = test_dataset, type = "response")#
true_labels <- test_data$target_variable  # Adjust this based on your data#
#
# Calculate ROC curve#
roc_curve <- roc(true_labels, pred_probs)#
#
# Plot ROC curve#
plot(roc_curve, main = "ROC Curve", col = "blue")#
abline(a = 0, b = 1, lwd = 2, lty = 2, col = "red")#
#
# Calculate AUC#
auc_value <- auc(roc_curve)#
#
# Convert predicted probabilities to binary predictions#
predictions <- ifelse(pred_probs >= 0.5, 1, 0)#
#
# Calculate confusion matrix#
conf_matrix <- confusionMatrix(data = factor(predictions, levels = c(0, 1)),#
                               reference = factor(true_labels, levels = c(0, 1)))#
#
# Extract accuracy from confusion matrix#
accuracy <- conf_matrix$overall['Accuracy']#
#
# Print AUC and accuracy#
print(paste("AUC:", auc_value))#
print(paste("Accuracy:", accuracy))
# Load required packages#
install.packages("pROC")#
library(pROC)#
#
# Get predicted probabilities from the model#
fitted_prob <- predict(reduced_model_8, type = "response")#
#
# Create ROC curve object#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve#
plot(roc_curve, main = "ROC Curve", col = "blue")#
abline(a = 0, b = 1, lwd = 2, lty = 2, col = "red")#
#
# Calculate AUC#
auc_value <- auc(roc_curve)#
print(paste("AUC:", auc_value))
# Assuming pi.2 contains the predicted probabilities and y contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(pi.2, decreasing = TRUE) #
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(pi.2 > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & y == 1)#
  fp <- sum(predicted_labels == 1 & y == 0)#
  fn <- sum(predicted_labels == 0 & y == 1)#
  tn <- sum(predicted_labels == 0 & y == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Calculate TPR*(1-FPR) for each threshold#
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)#
#
# Get the optimum threshold#
optimum_threshold <- thresholds[optimum_index]#
#
# Print the optimum threshold#
print(paste("Optimum Threshold:", round(optimum_threshold, 3)))
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Calculate TPR*(1-FPR) for each threshold#
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)#
#
# Get the optimum threshold#
optimum_threshold <- thresholds[optimum_index]#
#
# Print the optimum threshold#
print(paste("Optimum Threshold:", round(optimum_threshold, 3)))
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Calculate TPR*(1-FPR) for each threshold#
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)#
#
# Get the optimum threshold#
optimum_threshold <- thresholds[optimum_index]#
#
# Print the optimum threshold#
print(paste("Optimum Threshold:", round(optimum_threshold, 3)))#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve#
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)#
#
# Add diagonal line (random classifier)#
abline(a = 0, b = 1, lty = 2)#
#
# Add labels#
xlabel <- "False Positive Rate (FPR)"#
ylabel <- "True Positive Rate (TPR)"#
title <- "Receiver Operating Characteristic (ROC) Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = c("ROC Curve", "Random Classifier"), col = c("blue", "black"), lty = c(1, 2), lwd = c(2, 1), bty = "n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Calculate TPR*(1-FPR) for each threshold#
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)#
#
# Get the optimum threshold#
optimum_threshold <- thresholds[optimum_index]#
#
# Print the optimum threshold#
print(paste("Optimum Threshold:", round(optimum_threshold, 3)))#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve with FPR on X-axis and TPR on Y-axis#
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, legacy.axes = TRUE, grid = TRUE)#
#
# Add diagonal line (random classifier)#
abline(a = 0, b = 1, lty = 2)#
#
# Add labels#
xlabel <- "False Positive Rate (FPR)"#
ylabel <- "True Positive Rate (TPR)"#
title <- "Receiver Operating Characteristic (ROC) Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = c("ROC Curve", "Random Classifier"), col = c("blue", "black"), lty = c(1, 2), lwd = c(2, 1), bty = "n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Calculate TPR*(1-FPR) for each threshold#
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)#
#
# Get the optimum threshold#
optimum_threshold <- thresholds[optimum_index]#
#
# Print the optimum threshold#
print(paste("Optimum Threshold:", round(optimum_threshold, 3)))#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve with FPR on X-axis and TPR on Y-axis#
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, legacy.axes = TRUE, grid = TRUE)#
#
# Add diagonal line (random classifier)#
abline(a = 0, b = 1, lty = 2)#
#
# Add labels#
xlabel <- "False Positive Rate (FPR)"#
ylabel <- "True Positive Rate (TPR)"#
title <- "Receiver Operating Characteristic (ROC) Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = c("ROC Curve", "Random Classifier"), col = c("blue", "black"), lty = c(1, 2), lwd = c(2, 1), bty = "n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve with FPR on X-axis and TPR on Y-axis#
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, legacy.axes = TRUE, grid = TRUE)#
#
# Add labels#
xlabel <- "False Positive Rate (FPR)"#
ylabel <- "True Positive Rate (TPR)"#
title <- "Receiver Operating Characteristic (ROC) Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve with FPR on X-axis and TPR on Y-axis#
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, legacy.axes = TRUE, grid = TRUE)#
#
# Add labels#
xlabel <- "False Positive Rate (FPR)"#
ylabel <- "True Positive Rate (TPR)"#
title <- "Receiver Operating Characteristic (ROC) Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in descending order#
thresholds <- sort(fitted_prob, decreasing = TRUE)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using the pROC package#
# Install and load the pROC package#
install.packages("pROC")#
library(pROC)#
#
# Create ROC curve#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
#
# Plot ROC curve with FPR on X-axis and TPR on Y-axis#
plot(roc_curve, main = "ROC", col = "blue", lwd = 2, legacy.axes = TRUE, grid = TRUE)#
#
# Add labels#
xlabel <- "FPR"#
ylabel <- "TPR"#
title <- "ROC Curve"#
title(main = title, xlab = xlabel, ylab = ylabel)#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
plot(roc_curve)
tpr
TPR
FPR
plot(FPR,TPR)
data
plot(TPR,FPR)
plot(FPR,TPR)
plot(FPR,TPR,type="l")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in ascending order#
thresholds <- sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
fpr[which.max(tpr*(1-fpr))]
fpr[which.max(tpr_values*(1-fpr_values))]
fpr_values[which.max(tpr_values*(1-fpr_values))]
optimum_thresold = fpr_values[which.max(tpr_values*(1-fpr_values))]
optimum_thresold = tpr_values[which.max(tpr_values*(1-fpr_values))]
optimum_thresold = fpr_values[which.max(tpr_values*(1-fpr_values))]
optimum_thresold = tpr_values[which.max(tpr_values*(1-fpr_values))]
optimum_thresold
optimal_threshold <- thresholds[which.max(tpr_values * (1 - fpr_values))]
optimal_threshold
> optimum_thresold = fpr_values[which.max(tpr_values*(1-fpr_values))]#
> optimum_thresold = tpr_values[which.max(tpr_values*(1-fpr_values))]
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in ascending order#
thresholds <- sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy <- sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))
fitted_prob = predict(fullmodel)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in ascending order#
thresholds <- sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy <- sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in ascending order#
thresholds <- sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")
optimal_thresold
optimal_thresold
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy <- sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
# Finding thresold by Optimising TPR*(1-FPR)  ##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
# Sort predicted probabilities in ascending order#
thresholds <- sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values <- numeric(length(thresholds))#
fpr_values <- numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels <- ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] <- tp / (tp + fn)#
  fpr_values[i] <- fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy <- sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc_value <- auc(roc_curve)#
#
# Print AUC#
print(paste("AUC:", round(auc_value, 3)))
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
# threshold = sort(fitted_prob)  # You already have this line in your code#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Calculate AUC#
library(pROC)#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc_value <- auc(roc_curve)#
#
# Print AUC#
print(paste("AUC:", round(auc_value, 3)))
auc_roc <- sum(diff(fpr_values) * (tpr_values[-1] + tpr_values[-length(tpr_values)]) / 2)#
au#
# Print AUC-ROC#
cat("AUC-ROC:", auc_roc, "\n")
auc_roc <- sum(diff(fpr_values) * (tpr_values[-1] + tpr_values[-length(tpr_values)]) / 2)#
au#
# Print AUC-ROC#
cat("AUC-ROC:", auc_roc, "\n")
auc_roc <- sum(diff(fpr_values) * (tpr_values[-1] + tpr_values[-length(tpr_values)]) / 2)#
auc#
# Print AUC-ROC#
cat("AUC-ROC:", auc_roc, "\n")
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
# threshold = sort(fitted_prob)  # You already have this line in your code#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Calculate AUC#
library(pROC)#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc_value <- auc(roc_curve)#
#
# Print AUC#
print(paste("AUC:", round(auc_value, 3)))
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
# threshold = sort(fitted_prob)  # You already have this line in your code#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Calculate AUC#
library(pROC)#
roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc_value <- auc(roc_curve)#
#
# Print AUC#
print(paste("AUC:", round(auc_value, 3)))
> roc_curve <- roc(reduced_data_8$TenYearCHD, fitted_prob)#
Setting levels: control = 0, case = 1#
Setting direction: controls < cases#
> auc_value <- auc(roc_curve)
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)
auc(roc_curve)
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)
auc(roc_curve)
plot(roc_curve)
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")
line(roc_curve)
line(roc_curve)
lines(roc_curve)
lines(roc_curve)
lines(roc_curve)
lines(roc_curve)
plot(roc_curve)
lines(roc_curve)
lines(t(roc_curve))
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)
lines(fpr_values,fpr_values)
lines(fpr_values,fpr_values,lty=2)
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "blue", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "GREY", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Create the confusion matrix#
confusion_matrix <- table(Actual = reduced_data_8$TenYearCHD, Predicted = predicted_labels)#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Print confusion matrix#
cat("Confusion Matrix:\n")#
cat("\t\t\tActual\n")#
cat("\t\t\tPositive\tNegative\n")#
cat(sprintf("Predicted\tPositive\t%d\t\t%d\n", TP, FP))#
cat(sprintf("\t\tNegative\t%d\t\t%d\n", FN, TN))
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Print confusion matrix#
cat("Confusion Matrix:\n")#
cat("\t\t\tActual\n")#
cat("\t\t\tPositive\tNegative\n")#
cat(sprintf("Predicted\tPositive\t%d\t\t%d\n", TP, FP))#
cat(sprintf("\t\tNegative\t%d\t\t%d\n", FN, TN))
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Create confusion matrix#
confusion_matrix <- matrix(c(TP, FN, FP, TN), nrow = 2, byrow = TRUE, dimnames = list(Actual = c("Positive", "Negative"), Predicted = c("Positive", "Negative")))#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)
optimum_thresold
optimal_thresold
optimal_threshold
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
# Now, let's plot the ROC curve using base R plotting functions#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "GREY", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
# Add legend#
legend("bottomright", legend = "ROC Curve", col = "blue", lty = 1, lwd = 2, bty = "n")#
#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
optimal_threshold
optimal_threshold
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)''
tpr_fpr_product <- tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimum_index <- which.min(tpr_fpr_product)
optimum_thresold = #
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Ye", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
tpr_fpr_product = tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = which.min(tpr_fpr_product)#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
tpr_fpr_product = tpr_values * (1 - fpr_values)
optimal_thresold = which.min(tpr_fpr_product)
optimal_thresold
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]
optimal_thresold
tpr_fpr_product
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Ye", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
tpr_fpr_product = tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Yellow", lwd = 2, xlab = "FPR", ylab = "TPR")
tpr_fpr_product = tpr_values * (1 - fpr_values)
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
predicted_labels = ifelse(fitted_prob > optimal_thresold, 1, 0)
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Yellow", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
tpr_fpr_product = tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_thresold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)
# Determine predicted labels based on the optimal threshold#
predicted_labels <- ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP <- sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN <- sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Create confusion matrix#
confusion_matrix <- matrix(c(TP, FN, FP, TN), nrow = 2, byrow = TRUE, dimnames = list(Actual = c("Positive", "Negative"), Predicted = c("Positive", "Negative")))#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = numeric(length(thresholds))#
fpr_values = numeric(length(thresholds))#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Yellow", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
tpr_fpr_product = tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_thresold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)#
#Findign Out Confusion Matrix #
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Create confusion matrix#
confusion_matrix = matrix(c(TP, FN, FP, TN), nrow = 2, byrow = TRUE, dimnames = list(Actual = c("Positive", "Negative"), Predicted = c("Positive", "Negative")))#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)
optiamal_thresold
optimal_thresold
# ======================================================== ##
#                    Final Code                            ##
# ======================================================== ##
rm(list=ls())#
#install.packages("lattice")#
# install.packages("caret")#
#install.packages("pROC")#
#install.packages("randomForest")#
#install.packages("olsrr")#
library(car)#
library(caTools)#
library(ggplot2)#
library(pROC)#
library(reshape2)#
library(randomForest)#
library(InformationValue)#
library(olsrr)#
set.seed(1234)#
#
data = read.csv("/Users/suchibratapatra/Desktop/Dissertation/maindata.csv")#
split = sample.split(data, SplitRatio = 0.8)#
training_data = data[split, ]#
testing_data = data[!split, ]#
# = = = = = = = = = = = ##
#  Correlation Heatmap  ##
# = = = = = = = = = = = ##
correlation_matrix = cor(data)#
melted_correlation = melt(correlation_matrix)#
ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +#
  geom_tile() + #
  geom_text(aes(label = sprintf("%.2f", value)), size = 3) +#
  scale_fill_gradient2(low = "#58390b", high = "#0f423c", midpoint = 0, limit = c(-1,1), name="Correlation", mid = "#FFFFFF") +#
  theme_minimal() +#
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +#
  coord_fixed() +#
  labs(x = "Variables", y = "Variables")#
# = = = = = = = = = = = = = ##
#  Converting into factors  ##
# = = = = = = = = = = = = = ##
data$male = as.factor(data$male)#
data$education = as.factor(data$education)#
data$currentSmoker = as.factor(data$currentSmoker)#
data$prevalentStroke = as.factor(data$prevalentStroke)#
data$prevalentHyp = as.factor(data$prevalentHyp)#
data$diabetes = as.factor(data$diabetes)#
data$TenYearCHD = as.factor(data$TenYearCHD)#
model = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
#
#===============================##
#   Plottting the VIF Values    ##
#===============================##
#
vif_values = vif(model)#
vif_df = data.frame(Variable = names(vif_values), VIF = unname(vif_values))#
#
ggplot(vif_df, aes(x = Variable, y = VIF, fill = VIF)) +#
  geom_bar(stat = "identity", color = "steelblue") +#
  geom_hline(yintercept = 5, linetype = "dashed", color = "red", size = 1) +#
  theme_minimal() +#
  labs(title = "Plotting of the VIF Values", y = "VIF Value", x = "") +#
  coord_cartesian(ylim = c(0, max(vif_df$VIF) + 1)) + # Adjust y-axis limits#
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Angle the x-axis text#
#=========================================##
# Significance of the predictor variables ##
#=========================================##
x = summary(fullmodel)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
walds_t = as.numeric(estimates/sqrt(se))#
significance = numeric(15)#
for(i in 1:15){#
    if(abs(walds_t[i])>1.96){#
        significance[i]= "Not Significant"#
    }else{#
        significance[i]="Significant"#
    }#
}#
data.frame(names(training_data)[-16],walds_t,significance)#
Odds_Ratio = exp(estimates)#
#======================================##
# Selection of the Best Model          ##
#======================================##
#
# ============#
# Full Model#
# ============#
fullmodel = glm(TenYearCHD ~ ., data = training_data, family = binomial(link = "logit"))#
AIC_full_model = 2139.9#
summary(fullmodel)#
#
# =====================#
# Reduced Model -> 1#
# =====================#
x = summary(fullmodel);x#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_1 = training_data[-z+1]#
reduced_model_1 = glm(TenYearCHD ~ ., data = reduced_data_1, family = binomial(link = "logit"))#
summary(reduced_model_1)#
AIC_Reduced_Model_1 = 2138#
# =====================#
# Reduced Model -> 2#
# =====================#
x = summary(reduced_model_1)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_2 = reduced_data_1[-z+1]#
reduced_model_2 = glm(TenYearCHD ~ ., data = reduced_data_2, family = binomial(link = "logit"))#
summary(reduced_model_2)#
AIC_Reduced_Model_2 = 2136.3#
# =====================#
# Reduced Model -> 3#
# =====================#
x = summary(reduced_model_2)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_3 = reduced_data_2[-z+1]#
reduced_model_3 = glm(TenYearCHD ~ ., data = reduced_data_3, family = binomial(link = "logit"))#
summary(reduced_model_3)#
AIC_Reduced_Model_3 = 2134.7#
# =====================#
# Reduced Model -> 4#
# =====================#
x = summary(reduced_model_3)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_4 = reduced_data_3[-z+1]#
reduced_model_4 = glm(TenYearCHD ~ ., data = reduced_data_4, family = binomial(link = "logit"))#
summary(reduced_model_4)#
AIC_Reduced_Model_4 = 2133.2#
# =====================#
# Reduced Model -> 5#
# =====================#
x = summary(reduced_model_4)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_5 = reduced_data_4[-z+1]#
reduced_model_5 = glm(TenYearCHD ~ ., data = reduced_data_5, family = binomial(link = "logit"))#
summary(reduced_model_5)#
AIC_Reduced_Model_5 = 2131.6#
# =====================#
# Reduced Model -> 6#
# =====================#
x = summary(reduced_model_5)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_6 = reduced_data_5[-z+1]#
reduced_model_6 = glm(TenYearCHD ~ ., data = reduced_data_6, family = binomial(link = "logit"))#
summary(reduced_model_6)#
AIC_Reduced_Model_6 = 2130.1#
# =====================#
# Reduced Model -> 7#
# =====================#
x = summary(reduced_model_6)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_7 = reduced_data_6[-z+1]#
reduced_model_7 = glm(TenYearCHD ~ ., data = reduced_data_7, family = binomial(link = "logit"))#
summary(reduced_model_7)#
AIC_Reduced_Model_7 = 2128.8#
# =====================#
# Reduced Model -> 8#
# =====================#
x = summary(reduced_model_7)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_8 = reduced_data_7[-z+1]#
reduced_model_8 = glm(TenYearCHD ~ ., data = reduced_data_8, family = binomial(link = "logit"))#
summary(reduced_model_8)#
AIC_Reduced_Model_7 = 2128#
# =====================#
# Reduced Model -> 9#
# =====================#
x = summary(reduced_model_8)#
y =	x$coefficients#
z = which.max(as.vector(y[,4]))#
reduced_data_9 = reduced_data_8[-z+1]#
reduced_model_9 = glm(TenYearCHD ~ ., data = reduced_data_9, family = binomial(link = "logit"))#
summary(reduced_model_9)#
Selected_Model = reduced_model_6#
fitted_prob = fitted(Selected_Model)#
#==============================================##
#Finding Out Odds ratio#
#==============================================##
x = summary(reduced_model_8)#
y = x$coefficients#
estimates = y[,1][-1]#
se = y[,2][-1]#
Odds_Ratio = as.data.frame(exp(estimates))#
Odds_Ratio#
names(summary(fullmodel))#
fitted_prob = predict(reduced_model_8)#
#
#=============================================##
#Finding Goosness of Fit for the reduced Model##
#=============================================##
# Assuming fitted_prob contains the predicted probabilities and reduced_data_8$TenYearCHD contains the actual labels#
#
thresholds = sort(fitted_prob)#
#
# Initialize arrays to store TPR and FPR values#
tpr_values = array()#
fpr_values = array()#
#
# Calculate TPR and FPR for each threshold#
for (i in 1:length(thresholds)) {#
  predicted_labels = ifelse(fitted_prob > thresholds[i], 1, 0)#
  tp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
  fp = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
  fn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
  tn = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
  tpr_values[i] = tp / (tp + fn)#
  fpr_values[i] = fp / (fp + tn)#
}#
#
plot(fpr_values, tpr_values, type = "l", main = "ROC Curve", col = "Yellow", lwd = 2, xlab = "FPR", ylab = "TPR")#
#
tpr_fpr_product = tpr_values * (1 - fpr_values)#
#
# Find the index of the threshold where TPR*(1-FPR) is minimum#
optimal_thresold = fpr_values[which.min(tpr_fpr_product)]#
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_thresold, 1, 0)#
#
# Calculate accuracy#
accuracy = sum(predicted_labels == reduced_data_8$TenYearCHD) / length(reduced_data_8$TenYearCHD)#
#
# Print accuracy#
print(paste("Accuracy of the model at the optimal threshold:", round(accuracy, 3)))#
#Finding out the AUC Value#
roc_curve = roc(reduced_data_8$TenYearCHD, fitted_prob)#
auc(roc_curve)#
lines(fpr_values,fpr_values,lty=2)#
#Findign Out Confusion Matrix #
# Determine predicted labels based on the optimal threshold#
predicted_labels = ifelse(fitted_prob > optimal_threshold, 1, 0)#
#
# Calculate TP, FP, TN, FN#
TP = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 1)#
FP = sum(predicted_labels == 1 & reduced_data_8$TenYearCHD == 0)#
TN = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 0)#
FN = sum(predicted_labels == 0 & reduced_data_8$TenYearCHD == 1)#
#
# Create confusion matrix#
confusion_matrix = matrix(c(TP, FN, FP, TN), nrow = 2, byrow = TRUE, dimnames = list(Actual = c("Positive", "Negative"), Predicted = c("Positive", "Negative")))#
#
# Print confusion matrix#
print("Confusion Matrix:")#
print(confusion_matrix)
predicted_labels = ifelse(fitted_prob > optimal_thresold, 1, 0)
